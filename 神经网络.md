我很乐意帮你为Ataxx程序接入价值神经网络来替代当前的评估函数。目前你的评估函数相当简单，只是计算己方与对方棋子的差值：

```cpp
int evaluate(U64 board, U64 active) {
    int my = __builtin_popcountll(board & active);
    int opp = __builtin_popcountll((~board) & active);
    return my - opp;
}
```

接入价值神经网络可以显著提升AI的决策能力。以下是具体实施步骤：

## 1. 设计神经网络架构

为Ataxx设计一个适合的价值网络：

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class AtaxxConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(AtaxxConvBlock, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn = nn.BatchNorm2d(out_channels)
    
    def forward(self, x):
        return F.relu(self.bn(self.conv(x)))

class AtaxxValueNetwork(nn.Module):
    def __init__(self):
        super(AtaxxValueNetwork, self).__init__()
        
        # 输入层: 3通道 (当前玩家, 对手, 空位)
        self.conv1 = AtaxxConvBlock(3, 64)
        self.conv2 = AtaxxConvBlock(64, 64)
        self.conv3 = AtaxxConvBlock(64, 64)
        self.conv4 = AtaxxConvBlock(64, 64)
        
        # 全连接层
        self.fc1 = nn.Linear(64 * 7 * 7, 256)
        self.fc2 = nn.Linear(256, 128)
        self.fc3 = nn.Linear(128, 1)
        
    def forward(self, x):
        # 卷积层
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)
        
        # 展平
        x = x.view(-1, 64 * 7 * 7)
        
        # 全连接层
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = torch.tanh(self.fc3(x))  # 输出范围[-1, 1]
        
        return x
    
    def save(self, filepath):
        torch.save(self.state_dict(), filepath)
    
    def load(self, filepath):
        self.load_state_dict(torch.load(filepath))

```

## 2. 训练神经网络

创建训练脚本：

```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import Dataset, DataLoader
import random

from value_network import AtaxxValueNetwork

# 自我博弈生成训练数据
class AtaxxGame:
    def __init__(self):
        self.board_size = 7
        self.board = np.zeros((self.board_size, self.board_size), dtype=np.int8)
        # 初始棋盘设置
        self.board[0, 0] = self.board[6, 6] = 1  # 黑方
        self.board[0, 6] = self.board[6, 0] = -1  # 白方
        self.current_player = 1  # 黑方先手
        
    def get_state_tensor(self):
        """将棋盘状态转换为3通道tensor"""
        player_channel = np.zeros((self.board_size, self.board_size), dtype=np.float32)
        opponent_channel = np.zeros((self.board_size, self.board_size), dtype=np.float32)
        empty_channel = np.zeros((self.board_size, self.board_size), dtype=np.float32)
        
        for i in range(self.board_size):
            for j in range(self.board_size):
                if self.board[i, j] == self.current_player:
                    player_channel[i, j] = 1
                elif self.board[i, j] == -self.current_player:
                    opponent_channel[i, j] = 1
                else:
                    empty_channel[i, j] = 1
                    
        return np.stack([player_channel, opponent_channel, empty_channel])
    
    def get_legal_moves(self):
        """获取合法移动列表"""
        moves = []
        for x in range(self.board_size):
            for y in range(self.board_size):
                if self.board[x, y] == self.current_player:
                    # 克隆移动
                    for dx in range(-1, 2):
                        for dy in range(-1, 2):
                            if dx == 0 and dy == 0:
                                continue
                            nx, ny = x + dx, y + dy
                            if 0 <= nx < self.board_size and 0 <= ny < self.board_size and self.board[nx, ny] == 0:
                                moves.append((x, y, nx, ny, "clone"))
                    
                    # 跳跃移动
                    for dx in range(-2, 3):
                        for dy in range(-2, 3):
                            if abs(dx) <= 1 and abs(dy) <= 1:
                                continue
                            if abs(dx) > 2 or abs(dy) > 2:
                                continue
                            nx, ny = x + dx, y + dy
                            if 0 <= nx < self.board_size and 0 <= ny < self.board_size and self.board[nx, ny] == 0:
                                moves.append((x, y, nx, ny, "jump"))
        
        return moves
    
    def make_move(self, move):
        """执行移动并返回新的棋盘状态"""
        x0, y0, x1, y1, move_type = move
        
        if move_type == "jump":
            self.board[x0, y0] = 0  # 原位置置空
        
        self.board[x1, y1] = self.current_player  # 新位置放置棋子
        
        # 捕获相邻敌方棋子
        for dx in range(-1, 2):
            for dy in range(-1, 2):
                if dx == 0 and dy == 0:
                    continue
                nx, ny = x1 + dx, y1 + dy
                if 0 <= nx < self.board_size and 0 <= ny < self.board_size and self.board[nx, ny] == -self.current_player:
                    self.board[nx, ny] = self.current_player
        
        # 切换玩家
        self.current_player = -self.current_player
        
        return self.get_state_tensor()
    
    def get_winner(self):
        """检查游戏是否结束并返回赢家"""
        black_count = np.sum(self.board == 1)
        white_count = np.sum(self.board == -1)
        empty_count = np.sum(self.board == 0)
        
        # 如果一方没有棋子，或者棋盘已满
        if black_count == 0 or white_count == 0 or empty_count == 0:
            return 1 if black_count > white_count else (-1 if white_count > black_count else 0)
        
        # 检查双方是否都无法移动
        black_moves = len(self.get_legal_moves())
        self.current_player = -self.current_player
        white_moves = len(self.get_legal_moves())
        self.current_player = -self.current_player
        
        if black_moves == 0 and white_moves == 0:
            return 1 if black_count > white_count else (-1 if white_count > black_count else 0)
        
        return None  # 游戏尚未结束

# 数据集类
class AtaxxDataset(Dataset):
    def __init__(self, states, values):
        self.states = states
        self.values = values
        
    def __len__(self):
        return len(self.states)
    
    def __getitem__(self, idx):
        return self.states[idx], self.values[idx]

# 自我博弈生成数据
def generate_self_play_data(num_games):
    states = []
    values = []
    
    for _ in range(num_games):
        game = AtaxxGame()
        game_states = []
        
        # 游戏主循环
        while game.get_winner() is None:
            legal_moves = game.get_legal_moves()
            if not legal_moves:
                game.current_player = -game.current_player
                continue
                
            # 随机选择移动
            move = random.choice(legal_moves)
            
            # 保存状态
            game_states.append((game.get_state_tensor(), game.current_player))
            
            # 执行移动
            game.make_move(move)
        
        # 获取游戏结果
        winner = game.get_winner()
        
        # 分配价值
        for state, player in game_states:
            states.append(state)
            values.append(winner * player)  # 获胜为1，失败为-1，平局为0
    
    return np.array(states), np.array(values).reshape(-1, 1)

# 训练函数
def train_network(model, num_epochs=10, batch_size=64):
    # 生成训练数据
    print("生成自我博弈数据...")
    states, values = generate_self_play_data(num_games=1000)
    
    # 创建数据集和加载器
    dataset = AtaxxDataset(torch.FloatTensor(states), torch.FloatTensor(values))
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # 优化器和损失函数
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # 训练循环
    print("开始训练...")
    for epoch in range(num_epochs):
        total_loss = 0
        for states_batch, values_batch in dataloader:
            # 前向传播
            outputs = model(states_batch)
            loss = criterion(outputs, values_batch)
            
            # 反向传播和优化
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}")
    
    print("训练完成！")
    return model

# 主函数
if __name__ == "__main__":
    # 创建网络模型
    model = AtaxxValueNetwork()
    
    # 训练网络
    trained_model = train_network(model)
    
    # 保存模型
    trained_model.save("ataxx_value_network.pth")
    print("模型已保存至 ataxx_value_network.pth")

```

## 3. 将神经网络集成到C++代码中

你需要使用一个支持深度学习推理的C++库，例如LibTorch (PyTorch的C++前端)或ONNX Runtime：

```cpp
#include <torch/script.h>
#include <iostream>
#include <vector>
#include <memory>

class AtaxxValueNet {
private:
    torch::jit::script::Module module;
    bool is_loaded;

public:
    AtaxxValueNet() : is_loaded(false) {}

    bool load(const std::string& model_path) {
        try {
            // 加载预训练的TorchScript模型
            module = torch::jit::load(model_path);
            module.eval();  // 设置为评估模式
            is_loaded = true;
            std::cout << "神经网络模型加载成功!" << std::endl;
            return true;
        } catch (const c10::Error& e) {
            std::cerr << "加载模型失败: " << e.what() << std::endl;
            return false;
        }
    }

    // 将bitboard转换为神经网络的输入格式
    torch::Tensor bitboardToTensor(U64 board, U64 active) {
        // 创建3个通道: 当前玩家, 对手, 空位
        std::vector<float> player_channel(MAX_CELLS, 0);
        std::vector<float> opponent_channel(MAX_CELLS, 0);
        std::vector<float> empty_channel(MAX_CELLS, 0);

        for (int i = 0; i < MAX_CELLS; i++) {
            U64 mask = 1ULL << i;
            if (active & mask) {
                if (board & mask) {
                    player_channel[i] = 1.0f;
                } else {
                    opponent_channel[i] = 1.0f;
                }
            } else {
                empty_channel[i] = 1.0f;
            }
        }

        // 创建输入张量
        auto options = torch::TensorOptions().dtype(torch::kFloat32);
        
        std::vector<torch::Tensor> channels;
        channels.push_back(torch::from_blob(player_channel.data(), {1, 7, 7}, options).clone());
        channels.push_back(torch::from_blob(opponent_channel.data(), {1, 7, 7}, options).clone());
        channels.push_back(torch::from_blob(empty_channel.data(), {1, 7, 7}, options).clone());
        
        // 合并所有通道
        torch::Tensor input = torch::cat(channels, 0);
        input = input.unsqueeze(0);  // 添加batch维度
        
        return input;
    }

    float evaluate(U64 board, U64 active) {
        if (!is_loaded) {
            // 如果模型未加载，回退到原始评估函数
            int my = __builtin_popcountll(board & active);
            int opp = __builtin_popcountll((~board) & active);
            return static_cast<float>(my - opp);
        }

        try {
            // 准备输入
            torch::Tensor input = bitboardToTensor(board, active);
            
            // 前向传播
            std::vector<torch::jit::IValue> inputs;
            inputs.push_back(input);
            torch::Tensor output = module.forward(inputs).toTensor();
            
            // 获取评估值
            float value = output.item<float>();
            
            return value * 100.0f;  // 放大到合适的范围
        } catch (const c10::Error& e) {
            std::cerr << "神经网络评估失败: " << e.what() << std::endl;
            // 出错时回退到原始评估函数
            int my = __builtin_popcountll(board & active);
            int opp = __builtin_popcountll((~board) & active);
            return static_cast<float>(my - opp);
        }
    }
};

// 修改后的negamax函数使用神经网络评估
int negamax(U64 board, U64 active, int depth, int alpha, int beta, U64 &outB, U64 &outA, AtaxxValueNet& net) {
    if (depth == 0) {
        return net.evaluate(board, active);
    }
    vector<pair<U64,U64>> moves;
    generate_moves(board, active, moves);
    int bestScore = INT_MIN;
    U64 bestB = board, bestA = active;
    for (auto &mv : moves) {
        U64 nb = mv.first, na = mv.second;
        int score = -negamax(~nb & FULL_MASK, na, depth-1, -beta, -alpha, outB, outA, net);
        if (score > bestScore) {
            bestScore = score;
            bestB = nb;
            bestA = na;
        }
        alpha = max(alpha, score);
        if (alpha >= beta) break;
    }
    outB = bestB;
    outA = bestA;
    return bestScore;
}

```

## 4. 转换PyTorch模型为TorchScript

为了在C++中使用PyTorch模型，需要将模型转换为TorchScript格式：

```python
import torch
from value_network import AtaxxValueNetwork

def convert_to_torchscript():
    # 加载训练好的模型
    model = AtaxxValueNetwork()
    model.load("ataxx_value_network.pth")
    model.eval()
    
    # 创建示例输入
    example_input = torch.zeros((1, 3, 7, 7), dtype=torch.float32)
    
    # 转换为TorchScript
    traced_script_module = torch.jit.trace(model, example_input)
    
    # 保存为TorchScript模型
    traced_script_module.save("ataxx_value_network_scripted.pt")
    print("已成功转换为TorchScript模型: ataxx_value_network_scripted.pt")

if __name__ == "__main__":
    convert_to_torchscript()

```

## 5. 修改主函数以使用神经网络

```cpp
int main(){
    ios::sync_with_stdio(false);
    cin.tie(nullptr);

    // —— 初始化位棋盘掩码 —— 
    for (int i = 0; i < MAX_CELLS; i++) {
        mask[i] = 1ULL << i;
    }
    // 预计算 delta
    vector<pair<int,int>> dirs;
    for (int dx=-2;dx<=2;dx++) for(int dy=-2;dy<=2;dy++){
        if (dx==0 && dy==0) continue;
        if (abs(dx)<=2 && abs(dy)<=2) dirs.emplace_back(dx,dy);
    }
    // 填 clonemask/jumpmask
    for (int x=0;x<7;x++) for(int y=0;y<7;y++){
        int i = idx(x,y);
        U64 cm=0, jm=0;
        for (auto &d: dirs) {
            int nx = x+d.first, ny = y+d.second;
            if (!inMap(nx,ny)) continue;
            int j = idx(nx,ny);
            if (abs(d.first)<=1 && abs(d.second)<=1) {
                cm |= mask[j];
            } else {
                jm |= mask[j];
            }
        }
        clonemask[i] = cm;
        jumpmask[i]  = jm;
    }

    // 初始化并加载神经网络
    AtaxxValueNet valueNet;
    valueNet.load("ataxx_value_network_scripted.pt");  // 加载神经网络模型

    // —— 初始化 gridInfo 与 Botzone 协议恢复 —— 
    gridInfo[0][0] = gridInfo[6][6] = 1;
    gridInfo[6][0] = gridInfo[0][6] = -1;

    int turnID;
    cin >> turnID;
    currBotColor = -1; // 初始假设白方
    int x0,y0,x1,y1;
    for (int t=0; t<turnID-1; t++) {
        cin >> x0>>y0>>x1>>y1;
        if (x1>=0) ProcStep(x0,y0,x1,y1, -currBotColor);
        else currBotColor = 1;
        cin >> x0>>y0>>x1>>y1;
        if (x1>=0) ProcStep(x0,y0,x1,y1, currBotColor);
    }
    // 本回合对方
    cin >> x0>>y0>>x1>>y1;
    if (x1>=0) ProcStep(x0,y0,x1,y1, -currBotColor);
    else currBotColor = 1;

    // 构造 bitboard
    U64 board = 0, active = 0;
    for (int i=0;i<7;i++) for(int j=0;j<7;j++){
        if (gridInfo[i][j]!=0) {
            active |= mask[idx(i,j)];
            if (gridInfo[i][j] == currBotColor) {
                board |= mask[idx(i,j)];
            }
        }
    }
    // 调用搜索（深度可根据需要调整）
    U64 nextB, nextA;
    int DEPTH = 7;
    negamax(board, active, DEPTH, INT_MIN/2, INT_MAX/2, nextB, nextA, valueNet);

    // 找到差异格子：从 board->nextB 和 active->nextA 推出走法
    U64 added = nextA & ~active;
    U64 removed = (active & ~nextA);
    int sx=-1, sy=-1, tx=-1, ty=-1;
    if (added) {
        int to = __builtin_ctzll(added);
        tx = to / BOARD_SIZE; ty = to % BOARD_SIZE;
    }
    if (removed) {
        int fr = __builtin_ctzll(removed);
        sx = fr / BOARD_SIZE; sy = fr % BOARD_SIZE;
    }
    // 如果没有 removed（克隆走法），则起点任取 added 邻近的己方原点
    if (sx<0 && added) {
        for (int d=0;d<MAX_CELLS;d++){
            if ((board & mask[d]) && (clonemask[d] & added)) {
                sx = d / BOARD_SIZE; sy = d % BOARD_SIZE;
                break;
            }
        }
    }

    // 输出结果
    if (sx<0) {
        cout << "-1 -1 -1 -1\n"; // pass
    } else {
        cout << sx << " " << sy << " " << tx << " " << ty << "\n";
    }
    return 0;
}

```

## 6. 编译环境设置

为了在C++中使用LibTorch，你需要适当配置编译环境：

```cmake
cmake_minimum_required(VERSION 3.0 FATAL_ERROR)
project(ataxx_bot)

# 设置C++标准
set(CMAKE_CXX_STANDARD 14)
set(CMAKE_CXX_STANDARD_REQUIRED TRUE)

# 查找LibTorch包
find_package(Torch REQUIRED)
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${TORCH_CXX_FLAGS}")

# 添加可执行文件
add_executable(ataxx_bot main.cpp)

# 链接LibTorch库
target_link_libraries(ataxx_bot "${TORCH_LIBRARIES}")

# 设置可执行文件的RPATH
set_target_properties(ataxx_bot PROPERTIES
    CXX_VISIBILITY_PRESET hidden
    CUDA_VISIBILITY_PRESET hidden
    POSITION_INDEPENDENT_CODE ON
)

# 如果使用CUDA
if(TORCH_CUDA_FOUND)
    target_compile_definitions(ataxx_bot PRIVATE WITH_CUDA)
endif()

```

## 7. 高级特性：状态特征提取

为进一步提升神经网络性能，可以添加更多特征：

```python
def extract_advanced_features(board, active, player):
    """生成更高级的特征表示"""
    features = []
    board_size = 7
    
    # 基本特征: 玩家棋子、对手棋子、空位
    player_pieces = np.zeros((board_size, board_size), dtype=np.float32)
    opponent_pieces = np.zeros((board_size, board_size), dtype=np.float32)
    empty_spaces = np.zeros((board_size, board_size), dtype=np.float32)
    
    for i in range(board_size):
        for j in range(board_size):
            if board[i][j] == player:
                player_pieces[i][j] = 1
            elif board[i][j] == -player:
                opponent_pieces[i][j] = 1
            else:
                empty_spaces[i][j] = 1
    
    features.extend([player_pieces, opponent_pieces, empty_spaces])
    
    # 特征1: 可克隆或跳跃区域
    player_mobility = np.zeros((board_size, board_size), dtype=np.float32)
    opponent_mobility = np.zeros((board_size, board_size), dtype=np.float32)
    
    for i in range(board_size):
        for j in range(board_size):
            if board[i][j] != 0:
                continue
                
            # 检查是否在当前玩家的克隆范围内
            for di in range(-1, 2):
                for dj in range(-1, 2):
                    if di == 0 and dj == 0:
                        continue
                    ni, nj = i + di, j + dj
                    if 0 <= ni < board_size and 0 <= nj < board_size:
                        if board[ni][nj] == player:
                            player_mobility[i][j] = 1
                        elif board[ni][nj] == -player:
                            opponent_mobility[i][j] = 1
    
    features.extend([player_mobility, opponent_mobility])
    
    # 特征2: 距离敌方棋子最近的距离
    player_distance = np.zeros((board_size, board_size), dtype=np.float32)
    opponent_distance = np.zeros((board_size, board_size), dtype=np.float32)
    
    for i in range(board_size):
        for j in range(board_size):
            if board[i][j] == player:
                # 找到离最近的敌方棋子的距离
                min_dist = float('inf')
                for oi in range(board_size):
                    for oj in range(board_size):
                        if board[oi][oj] == -player:
                            dist = max(abs(i - oi), abs(j - oj))
                            min_dist = min(min_dist, dist)
                
                if min_dist != float('inf'):
                    player_distance[i][j] = 1.0 / (min_dist + 1)
            
            elif board[i][j] == -player:
                # 找到离最近的己方棋子的距离
                min_dist = float('inf')
                for oi in range(board_size):
                    for oj in range(board_size):
                        if board[oi][oj] == player:
                            dist = max(abs(i - oi), abs(j - oj))
                            min_dist = min(min_dist, dist)
                
                if min_dist != float('inf'):
                    opponent_distance[i][j] = 1.0 / (min_dist + 1)
    
    features.extend([player_distance, opponent_distance])
    
    # 特征3: 控制区域 - 每一个空位周围己方/敌方棋子数量
    player_control = np.zeros((board_size, board_size), dtype=np.float32)
    opponent_control = np.zeros((board_size, board_size), dtype=np.float32)
    
    for i in range(board_size):
        for j in range(board_size):
            if board[i][j] == 0:
                player_count = 0
                opponent_count = 0
                
                for di in range(-1, 2):
                    for dj in range(-1, 2):
                        if di == 0 and dj == 0:
                            continue
                        ni, nj = i + di, j + dj
                        if 0 <= ni < board_size and 0 <= nj < board_size:
                            if board[ni][nj] == player:
                                player_count += 1
                            elif board[ni][nj] == -player:
                                opponent_count += 1
                
                player_control[i][j] = player_count / 8.0
                opponent_control[i][j] = opponent_count / 8.0
    
    features.extend([player_control, opponent_control])
    
    # 特征4: 棋子数量密度
    player_density = np.zeros((board_size, board_size), dtype=np.float32)
    opponent_density = np.zeros((board_size, board_size), dtype=np.float32)
    
    for i in range(board_size):
        for j in range(board_size):
            if board[i][j] != 0:
                continue
            
            # 计算周围3x3区域内的己方/敌方棋
```